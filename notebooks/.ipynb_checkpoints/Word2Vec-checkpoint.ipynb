{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trying with pre-trained Word2Vec models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"/Users/billydodds/Documents/Projects/Transactions_ML\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import StratifiedKFold # type: ignore\n",
    "from sklearn.preprocessing import StandardScaler # type: ignore\n",
    "\n",
    "\n",
    "\n",
    "from components.scripts.load_data import load_data\n",
    "from components.scripts.process_data import get_corpora, run_fold, scale\n",
    "from components.scripts.process_data import NLP_distances\n",
    "\n",
    "\n",
    "\n",
    "import multiprocess as multiprocessing # normal multiprocessing doesn't work in Jupyter for some reason\n",
    "\n",
    "# from gensim.models import Word2Vec\n",
    "\n",
    "# import random\n",
    "\n",
    "# import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>amount</th>\n",
       "      <th>description</th>\n",
       "      <th>category</th>\n",
       "      <th>date</th>\n",
       "      <th>weekday</th>\n",
       "      <th>desc_corpus</th>\n",
       "      <th>desc_features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50.0</td>\n",
       "      <td>direct credit 002962 citigroup ptyltd paddy walsh</td>\n",
       "      <td>wages</td>\n",
       "      <td>2020-07-27</td>\n",
       "      <td>0</td>\n",
       "      <td>direct direc dire dir credit credi cred cre ci...</td>\n",
       "      <td>direct credit citigroup ptyltd paddy walsh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-4.8</td>\n",
       "      <td>mcdonalds gladesville gladesville  nswau</td>\n",
       "      <td>food</td>\n",
       "      <td>2020-07-27</td>\n",
       "      <td>0</td>\n",
       "      <td>mcdonalds mcdonald mcdonal mcdona mcdon mcdo m...</td>\n",
       "      <td>mcdonalds gladesville</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-4.0</td>\n",
       "      <td>mcdonalds gladesville gladesville  nswau</td>\n",
       "      <td>food</td>\n",
       "      <td>2020-07-27</td>\n",
       "      <td>0</td>\n",
       "      <td>mcdonalds mcdonald mcdonal mcdona mcdon mcdo m...</td>\n",
       "      <td>mcdonalds gladesville</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50.0</td>\n",
       "      <td>transfer from margaret a jorgensen izzy tutoring</td>\n",
       "      <td>wages</td>\n",
       "      <td>2020-07-26</td>\n",
       "      <td>6</td>\n",
       "      <td>transfer transfe transf trans tran tra margare...</td>\n",
       "      <td>transfer margaret jorgensen izzy tutoring</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-14.5</td>\n",
       "      <td>chargrill mosman         mosman       au</td>\n",
       "      <td>food</td>\n",
       "      <td>2020-07-25</td>\n",
       "      <td>5</td>\n",
       "      <td>chargrill chargril chargri chargr charg char c...</td>\n",
       "      <td>chargrill mosman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>-36.0</td>\n",
       "      <td>liquorland 3638 glebe au aus card xx6725 value...</td>\n",
       "      <td>beers</td>\n",
       "      <td>2019-09-11</td>\n",
       "      <td>2</td>\n",
       "      <td>liquorland liquorlan liquorla liquorl liquor l...</td>\n",
       "      <td>liquorland glebe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>-42.2</td>\n",
       "      <td>uberuae_eats sydney au aus card xx6725 value d...</td>\n",
       "      <td>food</td>\n",
       "      <td>2019-09-09</td>\n",
       "      <td>0</td>\n",
       "      <td>uberuae uberua uberu uber ube eats eat sydney ...</td>\n",
       "      <td>uberuae eats sydney</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>-13.0</td>\n",
       "      <td>eastern suburbs dist bellevue hill ns aus card...</td>\n",
       "      <td>beers</td>\n",
       "      <td>2019-09-06</td>\n",
       "      <td>4</td>\n",
       "      <td>eastern easter easte east eas suburbs suburb s...</td>\n",
       "      <td>eastern suburbs dist bellevue hill</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598</th>\n",
       "      <td>19.0</td>\n",
       "      <td>return uberuae_eats sydney au aus card xx6725 ...</td>\n",
       "      <td>food</td>\n",
       "      <td>2019-09-09</td>\n",
       "      <td>0</td>\n",
       "      <td>return retur retu ret uberuae uberua uberu ube...</td>\n",
       "      <td>return uberuae eats sydney</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>-5.0</td>\n",
       "      <td>mcdonaldscamperdownca camperdown   nswau</td>\n",
       "      <td>food</td>\n",
       "      <td>2019-09-11</td>\n",
       "      <td>2</td>\n",
       "      <td>mcdonaldscamperdownca mcdonaldscamperdownc mcd...</td>\n",
       "      <td>mcdonaldscamperdownca camperdown</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>600 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     amount                                        description category  \\\n",
       "0      50.0  direct credit 002962 citigroup ptyltd paddy walsh    wages   \n",
       "1      -4.8           mcdonalds gladesville gladesville  nswau     food   \n",
       "2      -4.0           mcdonalds gladesville gladesville  nswau     food   \n",
       "3      50.0   transfer from margaret a jorgensen izzy tutoring    wages   \n",
       "4     -14.5           chargrill mosman         mosman       au     food   \n",
       "..      ...                                                ...      ...   \n",
       "595   -36.0  liquorland 3638 glebe au aus card xx6725 value...    beers   \n",
       "596   -42.2  uberuae_eats sydney au aus card xx6725 value d...     food   \n",
       "597   -13.0  eastern suburbs dist bellevue hill ns aus card...    beers   \n",
       "598    19.0  return uberuae_eats sydney au aus card xx6725 ...     food   \n",
       "599    -5.0           mcdonaldscamperdownca camperdown   nswau     food   \n",
       "\n",
       "          date  weekday                                        desc_corpus  \\\n",
       "0   2020-07-27        0  direct direc dire dir credit credi cred cre ci...   \n",
       "1   2020-07-27        0  mcdonalds mcdonald mcdonal mcdona mcdon mcdo m...   \n",
       "2   2020-07-27        0  mcdonalds mcdonald mcdonal mcdona mcdon mcdo m...   \n",
       "3   2020-07-26        6  transfer transfe transf trans tran tra margare...   \n",
       "4   2020-07-25        5  chargrill chargril chargri chargr charg char c...   \n",
       "..         ...      ...                                                ...   \n",
       "595 2019-09-11        2  liquorland liquorlan liquorla liquorl liquor l...   \n",
       "596 2019-09-09        0  uberuae uberua uberu uber ube eats eat sydney ...   \n",
       "597 2019-09-06        4  eastern easter easte east eas suburbs suburb s...   \n",
       "598 2019-09-09        0  return retur retu ret uberuae uberua uberu ube...   \n",
       "599 2019-09-11        2  mcdonaldscamperdownca mcdonaldscamperdownc mcd...   \n",
       "\n",
       "                                  desc_features  \n",
       "0    direct credit citigroup ptyltd paddy walsh  \n",
       "1                         mcdonalds gladesville  \n",
       "2                         mcdonalds gladesville  \n",
       "3     transfer margaret jorgensen izzy tutoring  \n",
       "4                              chargrill mosman  \n",
       "..                                          ...  \n",
       "595                            liquorland glebe  \n",
       "596                         uberuae eats sydney  \n",
       "597          eastern suburbs dist bellevue hill  \n",
       "598                  return uberuae eats sydney  \n",
       "599            mcdonaldscamperdownca camperdown  \n",
       "\n",
       "[600 rows x 7 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"./components/private_files/\"\n",
    "\n",
    "# Load in data\n",
    "data = load_data(path)\n",
    "# data = data.drop([\"description\", \"date\", \"desc_corpus\"], axis=1)\n",
    "data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('teachers', 0.7878414988517761), ('educator', 0.7609370946884155), ('Teacher', 0.7341679930686951), ('student', 0.7071880102157593), ('pupil', 0.7035911083221436), ('schoolteacher', 0.7021132111549377), ('school', 0.6894515752792358), ('classroom', 0.6704409122467041), ('instructor', 0.6594052910804749), ('professor', 0.6570422649383545)]\n",
      "0.3971077\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "\n",
    "model = KeyedVectors.load_word2vec_format('wiki-news-300d-1M.vec') # , limit=999999\n",
    "\n",
    "# model = FastText.load_fasttext_format('wiki-news-300d-1M.vec')\n",
    "\n",
    "print(model.most_similar('teacher'))\n",
    "# Output = [('headteacher', 0.8075869083404541), ('schoolteacher', 0.7955552339553833), ('teachers', 0.733420729637146), ('teaches', 0.6839243173599243), ('meacher', 0.6825737357139587), ('teach', 0.6285147070884705), ('taught', 0.6244685649871826), ('teaching', 0.6199781894683838), ('schoolmaster', 0.6037642955780029), ('lessons', 0.5812176465988159)]\n",
    "\n",
    "print(model.similarity('teacher', 'teaches'))\n",
    "# Output = 0.683924396754"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.30142558"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.similarity('transfer', 'food')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_similarity(corpus, desc):\n",
    "    if len(corpus) == 0:\n",
    "        return 100.0\n",
    "    min_distances = []\n",
    "    for feature in desc.split(\" \"):\n",
    "        min_dist = np.inf\n",
    "        for corp in corpus:                 # Find the minimum distance that each feature has to any corpus item (best possible match)\n",
    "            try:\n",
    "                dist = model.similarity(feature, corp)\n",
    "            except:\n",
    "                print(f\"Something happened: feature={feature}, corpus word={corp}\")\n",
    "                pass\n",
    "            if dist == 0.0:\n",
    "                min_dist = dist\n",
    "                break\n",
    "            if dist < min_dist:\n",
    "                min_dist = dist\n",
    "        min_distances.append(min_dist)\n",
    "    return np.mean(min_distances)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.40054637"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.similarity('life', 'transport')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>amount</th>\n",
       "      <th>category</th>\n",
       "      <th>weekday</th>\n",
       "      <th>desc_features</th>\n",
       "      <th>wages_word2vec_dist</th>\n",
       "      <th>food_word2vec_dist</th>\n",
       "      <th>transfer_word2vec_dist</th>\n",
       "      <th>life/wellbeing_word2vec_dist</th>\n",
       "      <th>shopping_word2vec_dist</th>\n",
       "      <th>transport_word2vec_dist</th>\n",
       "      <th>beers_word2vec_dist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50.0</td>\n",
       "      <td>wages</td>\n",
       "      <td>0</td>\n",
       "      <td>direct credit citigroup ptyltd paddy walsh</td>\n",
       "      <td>0.287817</td>\n",
       "      <td>0.291161</td>\n",
       "      <td>0.274149</td>\n",
       "      <td>0.191568</td>\n",
       "      <td>0.269021</td>\n",
       "      <td>0.273310</td>\n",
       "      <td>0.240262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-4.8</td>\n",
       "      <td>food</td>\n",
       "      <td>0</td>\n",
       "      <td>mcdonalds gladesville</td>\n",
       "      <td>0.383430</td>\n",
       "      <td>0.415638</td>\n",
       "      <td>0.106511</td>\n",
       "      <td>0.242880</td>\n",
       "      <td>0.300836</td>\n",
       "      <td>0.167045</td>\n",
       "      <td>0.339243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-4.0</td>\n",
       "      <td>food</td>\n",
       "      <td>0</td>\n",
       "      <td>mcdonalds gladesville</td>\n",
       "      <td>0.383430</td>\n",
       "      <td>0.415638</td>\n",
       "      <td>0.106511</td>\n",
       "      <td>0.242880</td>\n",
       "      <td>0.300836</td>\n",
       "      <td>0.167045</td>\n",
       "      <td>0.339243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50.0</td>\n",
       "      <td>wages</td>\n",
       "      <td>6</td>\n",
       "      <td>transfer margaret jorgensen izzy tutoring</td>\n",
       "      <td>0.282394</td>\n",
       "      <td>0.284726</td>\n",
       "      <td>0.390946</td>\n",
       "      <td>0.225050</td>\n",
       "      <td>0.298715</td>\n",
       "      <td>0.290110</td>\n",
       "      <td>0.236897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-14.5</td>\n",
       "      <td>food</td>\n",
       "      <td>5</td>\n",
       "      <td>chargrill mosman</td>\n",
       "      <td>0.229762</td>\n",
       "      <td>0.337490</td>\n",
       "      <td>0.232264</td>\n",
       "      <td>0.198551</td>\n",
       "      <td>0.210881</td>\n",
       "      <td>0.195119</td>\n",
       "      <td>0.339621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>-36.0</td>\n",
       "      <td>beers</td>\n",
       "      <td>2</td>\n",
       "      <td>liquorland glebe</td>\n",
       "      <td>0.250473</td>\n",
       "      <td>0.191607</td>\n",
       "      <td>0.183644</td>\n",
       "      <td>0.223171</td>\n",
       "      <td>0.141857</td>\n",
       "      <td>0.127702</td>\n",
       "      <td>0.165788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>-42.2</td>\n",
       "      <td>food</td>\n",
       "      <td>0</td>\n",
       "      <td>uberuae eats sydney</td>\n",
       "      <td>0.262487</td>\n",
       "      <td>0.361457</td>\n",
       "      <td>0.124382</td>\n",
       "      <td>0.264266</td>\n",
       "      <td>0.276971</td>\n",
       "      <td>0.231161</td>\n",
       "      <td>0.279078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>-13.0</td>\n",
       "      <td>beers</td>\n",
       "      <td>4</td>\n",
       "      <td>eastern suburbs dist bellevue hill</td>\n",
       "      <td>0.316791</td>\n",
       "      <td>0.299100</td>\n",
       "      <td>0.234319</td>\n",
       "      <td>0.278599</td>\n",
       "      <td>0.313198</td>\n",
       "      <td>0.264674</td>\n",
       "      <td>0.295740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598</th>\n",
       "      <td>19.0</td>\n",
       "      <td>food</td>\n",
       "      <td>0</td>\n",
       "      <td>return uberuae eats sydney</td>\n",
       "      <td>0.291466</td>\n",
       "      <td>0.345420</td>\n",
       "      <td>0.267226</td>\n",
       "      <td>0.276531</td>\n",
       "      <td>0.287215</td>\n",
       "      <td>0.300569</td>\n",
       "      <td>0.264575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>-5.0</td>\n",
       "      <td>food</td>\n",
       "      <td>2</td>\n",
       "      <td>mcdonaldscamperdownca camperdown</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>600 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     amount category  weekday                               desc_features  \\\n",
       "0      50.0    wages        0  direct credit citigroup ptyltd paddy walsh   \n",
       "1      -4.8     food        0                       mcdonalds gladesville   \n",
       "2      -4.0     food        0                       mcdonalds gladesville   \n",
       "3      50.0    wages        6   transfer margaret jorgensen izzy tutoring   \n",
       "4     -14.5     food        5                            chargrill mosman   \n",
       "..      ...      ...      ...                                         ...   \n",
       "595   -36.0    beers        2                            liquorland glebe   \n",
       "596   -42.2     food        0                         uberuae eats sydney   \n",
       "597   -13.0    beers        4          eastern suburbs dist bellevue hill   \n",
       "598    19.0     food        0                  return uberuae eats sydney   \n",
       "599    -5.0     food        2            mcdonaldscamperdownca camperdown   \n",
       "\n",
       "     wages_word2vec_dist  food_word2vec_dist  transfer_word2vec_dist  \\\n",
       "0               0.287817            0.291161                0.274149   \n",
       "1               0.383430            0.415638                0.106511   \n",
       "2               0.383430            0.415638                0.106511   \n",
       "3               0.282394            0.284726                0.390946   \n",
       "4               0.229762            0.337490                0.232264   \n",
       "..                   ...                 ...                     ...   \n",
       "595             0.250473            0.191607                0.183644   \n",
       "596             0.262487            0.361457                0.124382   \n",
       "597             0.316791            0.299100                0.234319   \n",
       "598             0.291466            0.345420                0.267226   \n",
       "599            -1.000000           -1.000000               -1.000000   \n",
       "\n",
       "     life/wellbeing_word2vec_dist  shopping_word2vec_dist  \\\n",
       "0                        0.191568                0.269021   \n",
       "1                        0.242880                0.300836   \n",
       "2                        0.242880                0.300836   \n",
       "3                        0.225050                0.298715   \n",
       "4                        0.198551                0.210881   \n",
       "..                            ...                     ...   \n",
       "595                      0.223171                0.141857   \n",
       "596                      0.264266                0.276971   \n",
       "597                      0.278599                0.313198   \n",
       "598                      0.276531                0.287215   \n",
       "599                     -1.000000               -1.000000   \n",
       "\n",
       "     transport_word2vec_dist  beers_word2vec_dist  \n",
       "0                   0.273310             0.240262  \n",
       "1                   0.167045             0.339243  \n",
       "2                   0.167045             0.339243  \n",
       "3                   0.290110             0.236897  \n",
       "4                   0.195119             0.339621  \n",
       "..                       ...                  ...  \n",
       "595                 0.127702             0.165788  \n",
       "596                 0.231161             0.279078  \n",
       "597                 0.264674             0.295740  \n",
       "598                 0.300569             0.264575  \n",
       "599                -1.000000            -1.000000  \n",
       "\n",
       "[600 rows x 11 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for cat in data.category.unique():\n",
    "    data[cat+\"_word2vec_dist\"] = [get_similarity(words, cat) for words in data.desc_features]\n",
    "    \n",
    "data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_fold_word2vec(X:pd.DataFrame, split, model, web_scrape=False, lookup=False, verbose=True, min_freq=0) -> float:\n",
    "    \n",
    "    \n",
    "    train_index, test_index = split\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = X_train.category, X_test.category\n",
    "    \n",
    "\n",
    "    corpus = get_corpora(X_train, min_freq=min_freq)\n",
    "    X_train = NLP_distances(X_train.drop('category', axis=1), corpus, desc_dist=get_similarity)\n",
    "    X_test = NLP_distances(X_test.drop('category', axis=1), corpus, get_similarity)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X_train)\n",
    "    X_train = scale(X_train, scaler)\n",
    "    X_test = scale(X_test, scaler)\n",
    "    \n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "    model_predictions = model.predict(X_test)\n",
    "    predictions = model_predictions\n",
    "\n",
    "    print(\"predictions: \", predictions) if verbose else None\n",
    "    print(\"actual: \", np.array(y_test)) if verbose else None\n",
    "    print(\"matches: \", predictions == np.array(y_test)) if verbose else None\n",
    "\n",
    "    acc = sum(predictions == y_test)/len(predictions)\n",
    "\n",
    "    if verbose and (web_scrape or lookup):\n",
    "        print(f\"corrections: {sum(corrections)} of {len(corrections)}\")\n",
    "        print(f\"Baseline (just lookup without ML model): {sum(baseline)/len(baseline)}\")\n",
    "    \n",
    "    print(acc) if verbose else None\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "NLP_distances() got an unexpected keyword argument 'desc_dist'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-83-63d2df492b57>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# pool.join()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mrun_fold_word2vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"desc_features\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfolds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDecisionTreeClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-82-e3bad232508b>\u001b[0m in \u001b[0;36mrun_fold_word2vec\u001b[0;34m(X, split, model, web_scrape, lookup, verbose, min_freq)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mcorpus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_corpora\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmin_freq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNLP_distances\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'category'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc_dist\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mget_similarity\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNLP_distances\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'category'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_similarity\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: NLP_distances() got an unexpected keyword argument 'desc_dist'"
     ]
    }
   ],
   "source": [
    "splitter = StratifiedKFold(n_splits=10, shuffle=True)\n",
    "folds = list(splitter.split(data.drop(\"category\", axis=1), data.category))\n",
    "accuracies = []\n",
    "def record(acc):\n",
    "    accuracies.append(acc)\n",
    "\n",
    "# pool = multiprocessing.Pool(min(multiprocessing.cpu_count(), 10))\n",
    "# for fold in folds:\n",
    "#     pool.apply_async(run_fold_word2vec, args=(data, fold, DecisionTreeClassifier, False, False, True), callback = record)\n",
    "# pool.close()\n",
    "# pool.join()\n",
    "\n",
    "run_fold_word2vec(data.drop(\"desc_features\", axis=1), folds[1], DecisionTreeClassifier(), False, False, True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
