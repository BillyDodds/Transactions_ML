{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"/Users/billydodds/Documents/Projects/Transactions_ML\")\n",
    "\n",
    "import re\n",
    "from typing import Dict, List, Any, Tuple, Callable, Union\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords', quiet=True)\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from components.scripts.process_data import clean, clean_chop, get_corpora, get_lookup, get_webscrape, NLP_distances\n",
    "from components.scripts.load_data import load_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# Set path\n",
    "path = \"./components/private_files/\"\n",
    "\n",
    "# Load in labels and join to data\n",
    "data = load_data(path)\n",
    "testing = data.iloc[0:50]\n",
    "testing.category = [np.nan]*len(testing.category)\n",
    "training = data.iloc[50::]\n",
    "\n",
    "model = DecisionTreeClassifier()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_to_corpora(corpora:Dict, row:pd.DataFrame):\n",
    "    row = row.to_dict()\n",
    "    category = list(row[\"category\"].values())[0]\n",
    "    corpus = list(row[\"desc_corpus\"].values())[0]\n",
    "    corpora[category] = list(\n",
    "        set(corpora[category]).union(set(corpus.split(\" \")))\n",
    "    )\n",
    "    return corpora\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "29 of 50 predictions were found without the model.\n\n     amount                                        description category  \\\n0      50.0  direct credit 002962 citigroup ptyltd paddy walsh    wages   \n1      -4.8           mcdonalds gladesville gladesville  nswau     food   \n2      -4.0           mcdonalds gladesville gladesville  nswau     food   \n3      50.0   transfer from margaret a jorgensen izzy tutoring    wages   \n4     -14.5           chargrill mosman         mosman       au     food   \n..      ...                                                ...      ...   \n595   -36.0  liquorland 3638 glebe au aus card xx6725 value...    beers   \n596   -42.2  uberuae_eats sydney au aus card xx6725 value d...     food   \n597   -13.0  eastern suburbs dist bellevue hill ns aus card...    beers   \n598    19.0  return uberuae_eats sydney au aus card xx6725 ...     food   \n599    -5.0           mcdonaldscamperdownca camperdown   nswau     food   \n\n          date  weekday                                        desc_corpus  \\\n0   2020-07-27        0  direct direc dire dir credit credi cred cre ci...   \n1   2020-07-27        0  mcdonalds mcdonald mcdonal mcdona mcdon mcdo m...   \n2   2020-07-27        0  mcdonalds mcdonald mcdonal mcdona mcdon mcdo m...   \n3   2020-07-26        6  transfer transfe transf trans tran tra margare...   \n4   2020-07-25        5  chargrill chargril chargri chargr charg char c...   \n..         ...      ...                                                ...   \n595 2019-09-11        2  liquorland liquorlan liquorla liquorl liquor l...   \n596 2019-09-09        0  uberuae uberua uberu uber ube eats eat sydney ...   \n597 2019-09-06        4  eastern easter easte east eas suburbs suburb s...   \n598 2019-09-09        0  return retur retu ret uberuae uberua uberu ube...   \n599 2019-09-11        2  mcdonaldscamperdownca mcdonaldscamperdownc mcd...   \n\n                                  desc_features  \n0    direct credit citigroup ptyltd paddy walsh  \n1                         mcdonalds gladesville  \n2                         mcdonalds gladesville  \n3     transfer margaret jorgensen izzy tutoring  \n4                              chargrill mosman  \n..                                          ...  \n595                            liquorland glebe  \n596                         uberuae eats sydney  \n597          eastern suburbs dist bellevue hill  \n598                  return uberuae eats sydney  \n599            mcdonaldscamperdownca camperdown  \n\n[579 rows x 7 columns]\n"
    }
   ],
   "source": [
    "testing\n",
    "training\n",
    "\n",
    "last_added = training.tail(1)\n",
    "\n",
    "# Get Webscraping\n",
    "if first:\n",
    "    google_preds = get_webscrape(testing, path)\n",
    "else:\n",
    "    google_preds = [np.nan]*len(testing)\n",
    "\n",
    "# Join from lookup table\n",
    "lookup_preds = get_lookup(training, testing)\n",
    "\n",
    "# Train model\n",
    "if first:\n",
    "    corpora = get_corpora(training)\n",
    "else:\n",
    "    corpora = add_to_corpora(corpora, last_added)\n",
    "\n",
    "\n",
    "X_train = NLP_distances(training, corpora)\n",
    "y_train = X_train.category\n",
    "X_train = X_train.drop('category', axis=1)\n",
    "\n",
    "X_test = NLP_distances(testing, corpora).drop('category', axis=1)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "model_preds = model.predict(X_test)\n",
    "\n",
    "X_test['model_preds'] = model_preds\n",
    "X_test['google_preds'] = google_preds\n",
    "X_test['lookup_preds'] = lookup_preds\n",
    "\n",
    "# Prioritise the lookup values over the google values\n",
    "corrections = [look if str(look) != \"nan\" else goog for goog, look in zip(google_preds, lookup_preds)]\n",
    "\n",
    "# Take correction if present, else go with model pick\n",
    "X_test['pred_category'] = [corr if str(corr) != \"nan\" else mod for corr, mod in zip(corrections, model_preds)]\n",
    "\n",
    "# Don't bother reviewing a label that has been found through lookup or google\n",
    "X_test['certain'] = [True if str(goog) != \"nan\" or str(look) != \"nan\" else False for goog, look in zip(google_preds, lookup_preds)]\n",
    "\n",
    "print(f\"{sum(X_test.certain)} of {len(X_test.certain)} predictions were found without the model.\\n\")\n",
    "\n",
    "# Merge categories back on raw data\n",
    "X_test = data.merge(X_test, left_index=True, right_index=True, how=\"inner\").drop(\"category\", axis=1)\n",
    "\n",
    "X_test = X_test.rename(columns={'amount_x':'amount', 'pred_category':'category', 'weekday_x':'weekday'})\n",
    "base_testing = X_test[['amount', 'description', 'category', 'date', 'weekday', 'desc_corpus', 'desc_features', 'certain']]\n",
    "\n",
    "\n",
    "certain = base_testing[base_testing.certain].drop(\"certain\", axis=1)\n",
    "certain[['amount']].to_csv(path + \"transactions_labelled.csv\", mode = 'a', header = False, index=False)\n",
    "\n",
    "# Append certainties to training for next iteration, redefine test set\n",
    "training = training.append(certain).sort_index()\n",
    "testing = base_testing[~base_testing.certain].drop(\"certain\", axis=1)\n",
    "\n",
    "\n",
    "# certain = certain[[\"date\", \"amount\", \"description\", \"category\"]]\n",
    "# Add certain transactions to transactions_labelled.csv\n",
    "# \n",
    "\n",
    "\n",
    "\n",
    "# X_test = X_test[[\"date\", \"amount_x\", \"description\", \"pred_category\", \"certain\"]]\n",
    "\n",
    "# # X_test.columns = [\"date\", \"amount\", \"description\", \"pred_category\", \"certain\"]\n",
    "# # certain = X_test[X_test.certain].drop(\"certain\", axis=1)\n",
    "# # certain = certain[[\"date\", \"amount\", \"description\", \"pred_category\"]]\n",
    "# # Add certain transactions to transactions_labelled.csv\n",
    "# # certain.to_csv(path + \"transactions_labelled.csv\", mode = 'a', header = False, index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define instructions\n",
    "\n",
    "classes = {1:'beers', 2:'food', 3:'life/wellbeing', 4:'shopping', 5:'transfer', 6:'transport', 7:'wages'}\n",
    "instr = \"\\n[â†µ] accept\\t\"\n",
    "for key, value in classes.items():\n",
    "    instr = instr + f\"[{key}] {value}\\t\"\n",
    "\n",
    "instr += \"\\n\"\n",
    "\n",
    "X_test = X_test.rename(columns={'amount_x':'amount', 'pred_category':'category', 'weekday_x':'weekday'})\n",
    "base_testing = X_test[['amount', 'description', 'category', 'date', 'weekday', 'desc_corpus', 'desc_features']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_correction(uncertain, instr):\n",
    "    print(\"-\"*130)\n",
    "    print(f\"{len(uncertain)} transactions to go\")\n",
    "    print(instr)\n",
    "    print(uncertain.iloc[[-1], :], \"\\n\")\n",
    "    while True:\n",
    "        inp = input(\"Correct class: \")\n",
    "        if inp == \"\":\n",
    "            break\n",
    "        try:\n",
    "            int(inp)\n",
    "        except ValueError:\n",
    "            print(f\"Input must be a number (the things in square brackets). Try again\")\n",
    "            continue\n",
    "        if int(inp) in classes.keys():\n",
    "            break\n",
    "        else:\n",
    "            print(f\"Input must be a valid number (1-7, or blank if you back my model). Try again\")\n",
    "            continue\n",
    "    changes.append(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "lookup_preds = get_lookup(training, testing)\n",
    "corpora = get_corpora(training)\n",
    "X_train = NLP_distances(training, corpora)\n",
    "y_train = X_train.category\n",
    "X_train = X_train.drop('category', axis=1)\n",
    "\n",
    "X_test = NLP_distances(testing, corpora).drop('category', axis=1)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "model_preds = model.predict(X_test)\n",
    "\n",
    "X_test['model_preds'] = model_preds\n",
    "X_test['google_preds'] = google_preds\n",
    "X_test['lookup_preds'] = lookup_preds\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "50.0"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "testing.at[0, \"amount\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "nan\n"
    }
   ],
   "source": [
    "print(str(np.NaN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}