{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"/Users/billydodds/Documents/Projects/Transactions_ML\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "# from sklearn.svm import LinearSVC\n",
    "# from sklearn.neighbors import KNeighborsClassifier\n",
    "# from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, BaggingClassifier\n",
    "# from sklearn.multiclass import OneVsRestClassifier, OneVsOneClassifier\n",
    "# from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from components.scripts.load_data import load_data\n",
    "from components.scripts.MyDecisionTree import MyDecisionTree\n",
    "from components.scripts.process_data import get_corpora, NLP_distances, run_fold\n",
    "\n",
    "import multiprocess as multiprocessing # normal multiprocessing doesn't work in Jupyter for some reason\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "# import random\n",
    "\n",
    "# import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-160-02329dc7a0c7>:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train[\"category\"] = y_train\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>amount</th>\n",
       "      <th>date</th>\n",
       "      <th>weekday</th>\n",
       "      <th>desc_features</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>560</th>\n",
       "      <td>-6.20</td>\n",
       "      <td>2019-09-25</td>\n",
       "      <td>2</td>\n",
       "      <td>mcdonalds stanmore</td>\n",
       "      <td>food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>-9.00</td>\n",
       "      <td>2020-02-10</td>\n",
       "      <td>0</td>\n",
       "      <td>apex petroleum west ryde</td>\n",
       "      <td>transport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557</th>\n",
       "      <td>-13.00</td>\n",
       "      <td>2019-09-24</td>\n",
       "      <td>1</td>\n",
       "      <td>alfred hotel mngmnt camperdown</td>\n",
       "      <td>beers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>-37.99</td>\n",
       "      <td>2020-02-27</td>\n",
       "      <td>3</td>\n",
       "      <td>eleven rozelle</td>\n",
       "      <td>transport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>-11.21</td>\n",
       "      <td>2020-02-02</td>\n",
       "      <td>6</td>\n",
       "      <td>aldi stores gladesvi gladesville</td>\n",
       "      <td>shopping</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>-7.40</td>\n",
       "      <td>2020-06-20</td>\n",
       "      <td>5</td>\n",
       "      <td>haps hotels gladesville</td>\n",
       "      <td>beers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>-4.20</td>\n",
       "      <td>2019-10-28</td>\n",
       "      <td>0</td>\n",
       "      <td>taste baguette universit</td>\n",
       "      <td>food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>-2.50</td>\n",
       "      <td>2020-02-13</td>\n",
       "      <td>3</td>\n",
       "      <td>sfs sydney</td>\n",
       "      <td>food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>519</th>\n",
       "      <td>-9.95</td>\n",
       "      <td>2019-10-18</td>\n",
       "      <td>4</td>\n",
       "      <td>mcdonalds stanmore</td>\n",
       "      <td>food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-6.40</td>\n",
       "      <td>2020-07-20</td>\n",
       "      <td>0</td>\n",
       "      <td>bp connect rozelle</td>\n",
       "      <td>food</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>450 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     amount       date  weekday                     desc_features   category\n",
       "560   -6.20 2019-09-25        2                mcdonalds stanmore       food\n",
       "238   -9.00 2020-02-10        0          apex petroleum west ryde  transport\n",
       "557  -13.00 2019-09-24        1    alfred hotel mngmnt camperdown      beers\n",
       "197  -37.99 2020-02-27        3                    eleven rozelle  transport\n",
       "286  -11.21 2020-02-02        6  aldi stores gladesvi gladesville   shopping\n",
       "..      ...        ...      ...                               ...        ...\n",
       "71    -7.40 2020-06-20        5           haps hotels gladesville      beers\n",
       "489   -4.20 2019-10-28        0          taste baguette universit       food\n",
       "237   -2.50 2020-02-13        3                        sfs sydney       food\n",
       "519   -9.95 2019-10-18        4                mcdonalds stanmore       food\n",
       "17    -6.40 2020-07-20        0                bp connect rozelle       food\n",
       "\n",
       "[450 rows x 5 columns]"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_data = load_data(\"CSVData.csv\")\n",
    "y = tr_data[~pd.isnull(tr_data.category)].category\n",
    "X = tr_data[~pd.isnull(tr_data.category)].drop(\"category\", axis=1)\n",
    "\n",
    "X = X.drop([\"description\", \"desc_corpus\"], axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y)\n",
    "\n",
    "X_train[\"category\"] = y_train\n",
    "# corpora = get_corpora(X_train)\n",
    "# X_train = X_train.drop(\"category\", axis=1)\n",
    "\n",
    "# X_train = NLP_distances(X_train, corpora)\n",
    "# X_test = NLP_distances(X_test, corpora)\n",
    "\n",
    "\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['food', 'gumption', 'food', 'coffee', 'food', 'sydney', 'food']\n",
      "Number of sentences: 450.\n",
      "Number of rows: 450.\n"
     ]
    }
   ],
   "source": [
    "sentences = []\n",
    "for desc, cat in zip(X_train.desc_features, X_train.category):\n",
    "    sentence = desc.split(\" \")\n",
    "#     categories = [cat for i in range(len(sentence))]\n",
    "    splice = []\n",
    "    for word in sentence:\n",
    "        splice.append(cat)\n",
    "        splice.append(word)\n",
    "    splice.append(cat)\n",
    "    \n",
    "    sentences.append(splice)\n",
    "    \n",
    "print(sentences[6])\n",
    "\n",
    "print(\"Number of sentences: {}.\".format(len(voc)))\n",
    "print(\"Number of rows: {}.\".format(len(X_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model = Word2Vec(min_count=0,\n",
    "                     window=1,\n",
    "                     size=150,\n",
    "#                      sample=6e-5, \n",
    "                     alpha=0.03, \n",
    "                     min_alpha=0.0007, \n",
    "                     negative=0,\n",
    "                     workers=16-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model.build_vocab(sentences, progress_per=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45023, 110940)"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.train(sentences, total_examples=w2v_model.corpus_count, epochs=30, report_delay=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model.init_sims(replace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.031985078"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.wv.similarity('eleven', 'food')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.038791016"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.wv.similarity('life/wellbeing', 'transport')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'amount': 5,\n",
       " 'weekday': 5,\n",
       " 'food_desc_dist': 1,\n",
       " 'transport_desc_dist': 1,\n",
       " 'beers_desc_dist': 1,\n",
       " 'shopping_desc_dist': 1,\n",
       " 'wages_desc_dist': 1,\n",
       " 'life/wellbeing_desc_dist': 1,\n",
       " 'transfer_desc_dist': 1}"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def get_similarity(words, cat):\n",
    "    sims = []\n",
    "    for word in words.split(\" \"):\n",
    "        try:\n",
    "            sims.append(w2v_model.wv.similarity(word, cat))\n",
    "        except KeyError:\n",
    "            pass\n",
    "    if len(sims) == 0:\n",
    "        return -1.0\n",
    "    return np.mean(sims)\n",
    "\n",
    "weights = {\"amount\":5, \"weekday\":5}\n",
    "\n",
    "for cat in X_train.category.unique():\n",
    "    weights[cat + \"_desc_dist\"] = 1\n",
    "#     X_train[\"word2vec_dist_\"+cat] = [get_similarity(desc, cat) for desc in X_train.desc_features]\n",
    "#     X_test[\"word2vec_dist_\"+cat] = [get_similarity(desc, cat) for desc in X_test.desc_features]\n",
    "\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.drop([\"desc_features\", \"category\", \"date\"], axis=1)\n",
    "X_test = X_test.drop([\"desc_features\", \"date\"], axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.78"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = DecisionTreeClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "predictions = model.predict(X_test)\n",
    "np.mean(predictions == y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_fold_word2vec(X:pd.DataFrame, split:Tuple[np.array, np.array], model:Any, web_scrape=False, lookup=False, verbose=True, min_freq=0) -> float:\n",
    "    train_index, test_index = split\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = X_train.category, X_test.category\n",
    "\n",
    "    # Web Scraping:\n",
    "    if web_scrape:\n",
    "        goog = [google(query, verbose) for query in X_test.desc_features]\n",
    "        web_predictions = np.array([categorise(goo, verbose) for goo in goog], dtype=object)\n",
    "    \n",
    "    if lookup:\n",
    "        table = pd.DataFrame(X_train[[\"desc_features\", \"category\"]].groupby([\"desc_features\"])[\"category\"].unique().apply(','.join))\n",
    "        table = table.reset_index()\n",
    "        table = table[~table.category.str.contains(\",\")]\n",
    "        lookup_predictions = np.array(X_test.drop(\"category\", axis=1).merge(table, on=\"desc_features\", how=\"left\", validate=\"many_to_one\").category, dtype=object)\n",
    "\n",
    "    corpus = get_corpora(X_train, min_freq=min_freq)\n",
    "    X_train = NLP_distances(X_train.drop('category', axis=1), corpus)\n",
    "    X_test = NLP_distances(X_test.drop('category', axis=1), corpus)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X_train)\n",
    "    X_train = scale(X_train, scaler)\n",
    "    X_test = scale(X_test, scaler)\n",
    "    \n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    model_predictions = model.predict(X_test)\n",
    "    predictions = model_predictions\n",
    "    \n",
    "\n",
    "    if web_scrape or lookup:\n",
    "        print(\"model: \", predictions, type(predictions)) if verbose else None\n",
    "        if web_scrape:\n",
    "            print(\"web: \", web_predictions, type(web_predictions)) if verbose else None\n",
    "            predictions = np.array([web if web != \"\" else mod for web, mod in zip(web_predictions, predictions)])\n",
    "        if lookup:\n",
    "            print(\"lookup: \", lookup_predictions, type(lookup_predictions)) if verbose else None\n",
    "            predictions = np.array([look if str(look) != 'nan' else pred for look, pred in zip(lookup_predictions, predictions)])\n",
    "        corrections = np.array([1 if pred!=mod else 0 for pred, mod in zip(predictions, model_predictions)])\n",
    "\n",
    "        baseline = np.array([1 if str(look) != 'nan' else 0 for look in lookup_predictions])\n",
    "\n",
    "    print(\"predictions: \", predictions) if verbose else None\n",
    "    print(\"actual: \", np.array(y_test)) if verbose else None\n",
    "    print(\"matches: \", predictions == np.array(y_test)) if verbose else None\n",
    "\n",
    "    acc = sum(predictions == y_test)/len(predictions)\n",
    "\n",
    "    if verbose and (web_scrape or lookup):\n",
    "        print(f\"corrections: {sum(corrections)} of {len(corrections)}\")\n",
    "        print(f\"Baseline (just lookup without ML model): {sum(baseline)/len(baseline)}\")\n",
    "    \n",
    "    print(acc) if verbose else None\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
